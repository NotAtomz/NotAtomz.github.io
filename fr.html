<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Facial Recognition System</title>
    <script defer src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
    <style>
        video, canvas {
            position: absolute;
            left: 0;
            top: 0;
        }
        #videoElement {
            width: 100%;
            height: auto;
            transform: scaleX(-1); /* Mirror the video feed for a natural front camera experience */
        }
        #overlay {
            width: 100%;
            height: auto;
        }
    </style>
</head>
<body>
    <h1>Facial Recognition System</h1>
    <video id="videoElement" autoplay></video>
    <canvas id="overlay"></canvas>

    <script>
        const video = document.getElementById('videoElement');
        const overlay = document.getElementById('overlay');
        const ctx = overlay.getContext('2d');
        let labeledDescriptors = [];

        async function setupCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { 
                        facingMode: 'user'  // Use the front camera
                    } 
                });
                video.srcObject = stream;
                await video.play();
                console.log("Camera feed started");
            } catch (error) {
                console.error("Error accessing the camera: ", error);
                alert("Error accessing the camera. Please ensure you have granted permission.");
            }
        }

        async function loadModels() {
            try {
                await faceapi.nets.ssdMobilenetv1.loadFromUri('/models');
                await faceapi.nets.faceRecognitionNet.loadFromUri('/models');
                await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
                console.log("Models loaded");
            } catch (error) {
                console.error("Error loading models: ", error);
            }
        }

        async function loadLabeledDescriptors() {
            const labels = ['Person1', 'Person2']; // Add your labeled data here
            return Promise.all(
                labels.map(async label => {
                    try {
                        const img = await faceapi.fetchImage(`/images/${label}.jpg`);
                        const detections = await faceapi.detectSingleFace(img).withFaceLandmarks().withFaceDescriptor();
                        return new faceapi.LabeledFaceDescriptors(label, [detections.descriptor]);
                    } catch (error) {
                        console.error(`Error processing image for ${label}: `, error);
                    }
                })
            );
        }

        async function start() {
            await loadModels();
            labeledDescriptors = await loadLabeledDescriptors();

            const faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, 0.6);

            video.addEventListener('play', async () => {
                overlay.width = video.videoWidth;
                overlay.height = video.videoHeight;

                setInterval(async () => {
                    const detections = await faceapi.detectAllFaces(video).withFaceLandmarks().withFaceDescriptors();
                    const resizedDetections = faceapi.resizeResults(detections, {
                        width: video.videoWidth,
                        height: video.videoHeight
                    });

                    ctx.clearRect(0, 0, overlay.width, overlay.height);

                    resizedDetections.forEach(detection => {
                        const match = faceMatcher.findBestMatch(detection.descriptor);
                        const box = detection.detection.box;
                        const text = match.toString();

                        ctx.strokeStyle = '#00FF00';
                        ctx.lineWidth = 2;
                        ctx.strokeRect(box.x, box.y, box.width, box.height);

                        ctx.fillStyle = '#00FF00';
                        ctx.font = '20px Arial';
                        const textWidth = ctx.measureText(text).width;
                        ctx.fillRect(box.x, box.y - 25, textWidth + 10, 25);
                        ctx.fillStyle = '#000000';
                        ctx.fillText(text, box.x + 5, box.y - 5);
                    });
                }, 100);
            });
        }

        setupCamera().then(start);
    </script>
</body>
</html>
